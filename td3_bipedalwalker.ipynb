{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install box2d-py\nimport gym\nenv = gym.make(\"LunarLander-v2\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-12T08:05:52.154704Z","iopub.execute_input":"2021-06-12T08:05:52.155040Z","iopub.status.idle":"2021-06-12T08:05:59.489099Z","shell.execute_reply.started":"2021-06-12T08:05:52.154965Z","shell.execute_reply":"2021-06-12T08:05:59.488209Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting box2d-py\n  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n\u001b[K     |████████████████████████████████| 448 kB 4.6 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: box2d-py\nSuccessfully installed box2d-py-2.3.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as Optim\nimport numpy as np\nfrom torch.distributions import MultivariateNormal\n\nclass Actor(nn.Module):\n  def __init__(self,input_dims,fc1_dims,fc2_dims,action_dims,device):\n    super(Actor,self).__init__()\n\n    self.fc1 = nn.Linear(input_dims,fc1_dims)\n    f1 = 1 / np.sqrt(self.fc1.weight.data.size()[0])\n    torch.nn.init.uniform_(self.fc1.weight.data, -f1, f1)\n    torch.nn.init.uniform_(self.fc1.bias.data, -f1, f1)\n    self.bn1 = nn.LayerNorm(fc1_dims)\n\n    self.fc2 = nn.Linear(fc1_dims,fc2_dims)\n    f2 = 1 / np.sqrt(self.fc2.weight.data.size()[0])\n    torch.nn.init.uniform_(self.fc2.weight.data, -f2, f2)\n    torch.nn.init.uniform_(self.fc2.bias.data, -f2, f2)\n    self.bn2 = nn.LayerNorm(fc2_dims)\n\n    f3 = 0.003\n    self.mu = nn.Linear(fc2_dims,action_dims)\n    torch.nn.init.uniform_(self.mu.weight.data, -f3, f3)\n    torch.nn.init.uniform_(self.mu.bias.data, -f3, f3)\n\n    self.device = device\n    self.to(self.device)\n  \n  def forward(self,state):\n\n    x = F.relu(self.bn1(self.fc1(state)))\n    x = F.relu(self.bn2(self.fc2(x)))\n\n    action_mu = torch.tanh(self.mu(x))\n\n    return action_mu\n\n\nclass Critic(nn.Module):\n  def __init__(self,input_dims,fc1_dims,fc2_dims,action_dims,device):\n    super(Critic,self).__init__()\n\n    self.fc1 = nn.Linear(input_dims,fc1_dims)\n    f1 = 1 / np.sqrt(self.fc1.weight.data.size()[0])\n    torch.nn.init.uniform_(self.fc1.weight.data, -f1, f1)\n    torch.nn.init.uniform_(self.fc1.bias.data, -f1, f1)\n    self.bn1 = nn.LayerNorm(fc1_dims)\n\n    self.fc2 = nn.Linear(fc1_dims,fc2_dims)\n    f2 = 1 / np.sqrt(self.fc2.weight.data.size()[0])\n    torch.nn.init.uniform_(self.fc2.weight.data, -f2, f2)\n    torch.nn.init.uniform_(self.fc2.bias.data, -f2, f2)\n    self.bn2 = nn.LayerNorm(fc2_dims)\n\n    self.action_value_layer = nn.Linear(action_dims,fc2_dims)\n\n    f3 = 0.003\n    self.q = nn.Linear(fc2_dims,1)\n    torch.nn.init.uniform_(self.q.weight.data, -f3, f3)\n    torch.nn.init.uniform_(self.q.bias.data, -f3, f3)\n\n    self.device = device\n    self.to(self.device)\n  \n  def forward(self,state,action):\n\n    state_value = F.relu(self.bn1(self.fc1(state)))\n    state_value = self.bn2(self.fc2(state_value))\n\n    action_value = F.relu(self.action_value_layer(action))\n\n    state_action_value = F.relu(torch.add(state_value,action_value))\n    state_action_value = self.q(state_action_value)\n\n    return state_action_value\n  \n\nclass Agent:\n  def __init__(self,alpha,beta,input_dims,fc1_dims,fc2_dims,action_dims,tau,env,action_std_decay_rate,device,\n                 min_action_std, gamma=0.99,max_size=1000000,batch_size=64,action_std_init=0.6,policy_delay=2,noise_clip=0.5,policy_noise=0.2):\n    \n    self.action_dims = action_dims\n    self.gamma = gamma\n    self.tau = tau\n    self.env = env\n    self.batch_size = batch_size\n    self.device = device\n\n    self.action_dims=action_dims\n    self.action_std_decay_rate = action_std_decay_rate\n    self.min_action_std = min_action_std\n\n    self.actor = Actor(input_dims=input_dims,fc1_dims=fc1_dims,fc2_dims=fc2_dims,action_dims=action_dims,device=device)\n    self.target_actor = Actor(input_dims=input_dims,fc1_dims=fc1_dims,fc2_dims=fc2_dims,action_dims=action_dims,device=device)\n\n    self.critic_1 = Critic(input_dims=input_dims,fc1_dims=fc1_dims,fc2_dims=fc2_dims,action_dims=action_dims,device=device)\n    self.target_critic_1 = Critic(input_dims=input_dims,fc1_dims=fc1_dims,fc2_dims=fc2_dims,action_dims=action_dims,device=device)\n    \n    self.critic_2 = Critic(input_dims=input_dims,fc1_dims=fc1_dims,fc2_dims=fc2_dims,action_dims=action_dims,device=device)\n    self.target_critic_2 = Critic(input_dims=input_dims,fc1_dims=fc1_dims,fc2_dims=fc2_dims,action_dims=action_dims,device=device)\n\n    self.critic_optimizer_1 = Optim.Adam(self.critic_1.parameters(),lr=beta)\n    self.critic_optimizer_2 = Optim.Adam(self.critic_2.parameters(),lr=beta)\n    self.actor_optimizer = Optim.Adam(self.actor.parameters(),lr=alpha)\n\n    self.action_std = action_std_init\n    self.action_var = torch.full((self.action_dims,), self.action_std * self.action_std).to(device)\n\n    self.policy_delay = policy_delay\n    self.noise_clip = noise_clip\n    self.policy_noise = policy_noise\n\n    self.mem_size = max_size\n    self.mem_cntr = 0\n    self.state_memory = np.zeros((self.mem_size, input_dims))\n    self.new_state_memory = np.zeros((self.mem_size, input_dims))\n    self.action_memory = np.zeros((self.mem_size,action_dims))\n    self.reward_memory = np.zeros((self.mem_size,1))\n    self.terminal_memory = np.zeros((self.mem_size,1), dtype=np.float32)\n\n    self.update_network_parameters(tau=1)\n\n  \n  def update_network_parameters(self, tau=None):\n        if tau is None:\n            tau = self.tau\n\n        actor_params = self.actor.named_parameters()\n        target_actor_params = self.target_actor.named_parameters()\n        critic_params_1 = self.critic_1.named_parameters()\n        target_critic_params_1 = self.target_critic_1.named_parameters()\n        critic_params_2 = self.critic_2.named_parameters()\n        target_critic_params_2 = self.target_critic_2.named_parameters()\n\n\n        actor_state_dict = dict(actor_params)\n        target_actor_dict = dict(target_actor_params)\n        critic_state_dict_1 = dict(critic_params_1)\n        target_critic_dict_1 = dict(target_critic_params_1)\n        critic_state_dict_2 = dict(critic_params_2)\n        target_critic_dict_2 = dict(target_critic_params_2)\n\n        for name in critic_state_dict_1:\n            critic_state_dict_1[name] = tau*critic_state_dict_1[name].clone() + \\\n                                      (1-tau)*target_critic_dict_1[name].clone()\n\n        self.target_critic_1.load_state_dict(critic_state_dict_1)\n\n\n        for name in critic_state_dict_2:\n            critic_state_dict_2[name] = tau*critic_state_dict_2[name].clone() + \\\n                                      (1-tau)*target_critic_dict_2[name].clone()\n\n        self.target_critic_2.load_state_dict(critic_state_dict_2)\n\n\n        for name in actor_state_dict:\n            actor_state_dict[name] = tau*actor_state_dict[name].clone() + \\\n                                      (1-tau)*target_actor_dict[name].clone()\n        self.target_actor.load_state_dict(actor_state_dict)\n\n\n  \n  \n  def set_action_std(self, new_action_std):\n    self.action_std = new_action_std\n    self.action_var = torch.full((self.action_dims,), self.action_std * self.action_std).to(self.device)\n\n  \n  \n  def decay_action_std(self):\n    print(\"--------------------------------------------------------------------------------------------\")\n    \n    self.action_std = self.action_std - self.action_std_decay_rate\n    self.action_std = round(self.action_std, 4)\n    if (self.action_std <= self.min_action_std):\n      self.action_std = self.min_action_std\n      print(\"setting actor output action_std to min_action_std : \", self.action_std)\n      self.set_action_std(self.action_std)\n    else:\n      print(\"setting actor output action_std to : \", self.action_std)\n      self.set_action_std(self.action_std)\n    \n    print(\"--------------------------------------------------------------------------------------------\")\n\n  \n  def remember(self,state,action,reward,new_state,done):\n    index = self.mem_cntr % self.mem_size\n    self.state_memory[index] = state\n    self.action_memory[index] = action\n    self.reward_memory[index] = reward\n    self.new_state_memory[index] = new_state\n    self.terminal_memory[index] = float(1- done)\n    self.mem_cntr += 1\n  \n  \n  def choose_action(self,observation):\n    self.actor.eval()\n    with torch.no_grad():\n      state = torch.FloatTensor(observation).to(self.actor.device)\n      action_mean = self.actor.forward(state).to(self.actor.device)\n      cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n      dist = MultivariateNormal(action_mean, cov_mat)\n      \n    action = dist.sample()\n    low = self.env.action_space.low[0]\n    high = self.env.action_space.high[0]\n    action = torch.clamp(action,low,high)\n    \n    self.actor.train()\n      \n    return action.detach().cpu().numpy().flatten()\n  \n\n  def learn(self,n_iter):\n\n    for k in range(n_iter):\n      if self.mem_cntr < self.batch_size:\n        return\n      else:\n        max_mem = min(self.mem_cntr, self.mem_size)\n\n      batch = np.random.choice(max_mem, self.batch_size)\n\n      states = self.state_memory[batch]\n      actions = self.action_memory[batch]\n      rewards = self.reward_memory[batch]\n      next_states = self.new_state_memory[batch]\n      terminals = self.terminal_memory[batch]\n\n      rewards = torch.tensor(rewards, dtype=torch.float).to(self.critic_1.device)\n      terminals = torch.tensor(terminals).to(self.critic_1.device)\n      next_states = torch.tensor(next_states, dtype=torch.float).to(self.critic_1.device)\n      actions = torch.tensor(actions, dtype=torch.float).to(self.critic_1.device)\n      states = torch.tensor(states, dtype=torch.float).to(self.critic_1.device)\n\n      self.target_actor.eval()\n      self.target_critic_1.eval()\n      self.critic_1.eval()\n      self.target_critic_2.eval()\n      self.critic_2.eval()\n\n      next_actions = self.target_actor.forward(next_states)\n      noise =  torch.normal(0,self.policy_noise, size=actions.shape).to(self.device)\n      noise = noise.clamp(-self.noise_clip, self.noise_clip)\n      next_actions = (next_actions + noise)\n      next_actions = torch.clamp(next_actions,self.env.action_space.low[0],self.env.action_space.high[0])\n\n      next_critic_value_1 = self.target_critic_1.forward(next_states,next_actions)\n      next_critic_value_2 = self.target_critic_2.forward(next_states,next_actions)\n      next_critic_value = torch.min(next_critic_value_1,next_critic_value_2)\n      critic_value_1 = self.critic_1.forward(states,actions)\n      critic_value_2 = self.critic_2.forward(states,actions)\n\n      targets = rewards + self.gamma*next_critic_value*terminals\n      targets = torch.tensor(targets).to(self.critic_1.device)\n      targets = targets.view(self.batch_size, 1)\n\n      self.critic_1.train()\n      self.critic_optimizer_1.zero_grad()\n      critic_loss_1 = F.mse_loss(targets, critic_value_1)\n      critic_loss_1.backward()\n      self.critic_optimizer_1.step()\n\n      self.critic_2.train()\n      self.critic_optimizer_2.zero_grad()\n      critic_loss_2 = F.mse_loss(targets, critic_value_2)\n      critic_loss_2.backward()\n      self.critic_optimizer_2.step()\n\n      if k%self.policy_delay == 0:\n        \n        self.critic_1.eval()\n        mu = self.actor.forward(states)\n        self.actor.train()\n        actor_loss = -self.critic_1.forward(states,mu)\n        self.actor_optimizer.zero_grad()\n        actor_loss.mean().backward()\n        self.actor_optimizer.step()\n        \n        self.update_network_parameters()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T08:06:15.891584Z","iopub.execute_input":"2021-06-12T08:06:15.891949Z","iopub.status.idle":"2021-06-12T08:06:17.083997Z","shell.execute_reply.started":"2021-06-12T08:06:15.891916Z","shell.execute_reply":"2021-06-12T08:06:17.083105Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import gym\nimport numpy as np\n\nenv = gym.make('LunarLanderContinuous-v2')\nagent = Agent(alpha=0.001, beta=0.001, input_dims=8, tau=0.001, env=env,action_std_decay_rate=0.05,gamma=0.99,\n                 min_action_std=0.05,batch_size=128, fc1_dims=400, fc2_dims=300, action_dims=2,action_std_init=0.2,device='cuda')\n\naction_std_decay_freq = int(7.5e4) \n#action_std_decay_freq = int(2000) \n\nscore_history = []\ntimesteps = 0\nfor i in range(5000):\n    obs = env.reset()\n    done = False\n    score = 0\n    t = 0\n    while not done:\n        act = agent.choose_action(obs)\n        new_state, reward, done, info = env.step(act)\n        agent.remember(obs, act, reward, new_state, int(done))\n        score += reward\n        obs = new_state\n        timesteps += 1\n        \n        if timesteps % action_std_decay_freq == 0:\n           pass\n           # agent.decay_action_std()\n            \n        if done:\n            agent.learn(t)\n            break\n        #env.render()\n        t += 1\n    score_history.append(score)\n\n    if i % 10 == 0:\n        print('episode ', i, 'score %.2f' % score,\n          'trailing 10 games avg %.3f' % np.mean(score_history[-10:]),\n          'trailing 100 games avg %.3f' % np.mean(score_history[-100:]),\n          'timesteps:',timesteps)\n    else:\n        print('episode ', i, 'score %.2f' % score,\n          'timesteps:',timesteps)\n      \n    avg_100 = np.mean(score_history[-100:])\n    if avg_100 >= 210:\n      print(\"####SOLVED!!####\")\n      break\n\n\navg_score = 0\nprint(\"\")\nfor i in range(50):\n  obs = env.reset()\n  done = False\n  score = 0\n  while not done:\n    act = agent.choose_action(obs)\n    new_state, reward, done, info = env.step(act)\n    obs = new_state\n    score += reward\n  avg_score += score\n  print(\"Episode Reward:\",score)\n\nprint(\"\")\nprint(avg_score/50)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:57:53.690831Z","iopub.execute_input":"2021-06-11T07:57:53.691168Z","iopub.status.idle":"2021-06-11T09:43:56.40455Z","shell.execute_reply.started":"2021-06-11T07:57:53.691141Z","shell.execute_reply":"2021-06-11T09:43:56.402905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gym\nimport numpy as np\n\nenv = gym.make('BipedalWalker-v3')\nagent = Agent(alpha=0.001, beta=0.001, input_dims=24, tau=0.005, env=env,action_std_decay_rate=0.05,gamma=0.99,\n                 min_action_std=0.1,batch_size=256, fc1_dims=512, fc2_dims=512, action_dims=4,action_std_init=0.4,device='cuda',policy_delay=3,policy_noise=0.15,noise_clip=0.2)\n\naction_std_decay_freq = int(5e4) \n#action_std_decay_freq = int(2000) \n\nscore_history = []\ntimesteps = 0\nfor i in range(5000):\n    obs = env.reset()\n    done = False\n    score = 0\n    t = 0\n    while not done:\n        act = agent.choose_action(obs)\n        new_state, reward, done, info = env.step(act)\n        agent.remember(obs, act, reward, new_state, int(done))\n        score += reward\n        obs = new_state\n        timesteps += 1\n        \n        if timesteps % action_std_decay_freq == 0:\n           agent.decay_action_std()\n            \n        if done:\n            agent.learn(t)\n            break\n        #env.render()\n        t += 1\n    score_history.append(score)\n\n    if i % 10 == 0:\n        print('episode ', i, 'score %.2f' % score,\n          'trailing 10 games avg %.3f:' % np.mean(score_history[-10:]),\n          'trailing 100 games avg %.3f:' % np.mean(score_history[-100:]),\n          'timesteps:',timesteps)\n    else:\n        print('episode ', i, 'score %.2f' % score,\n          'timesteps:',timesteps)\n      \n    avg_100 = np.mean(score_history[-100:])\n    if avg_100 >= 290:\n      print(\"####SOLVED!!####\")\n      break\n\n\navg_score = 0\nprint(\"\")\nfor i in range(50):\n  obs = env.reset()\n  done = False\n  score = 0\n  while not done:\n    act = agent.choose_action(obs)\n    new_state, reward, done, info = env.step(act)\n    obs = new_state\n    score += reward\n  avg_score += score\n  print(\"Episode Reward:\",score)\n\nprint(\"\")\nprint(avg_score/50)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:06:39.305027Z","iopub.execute_input":"2021-06-12T12:06:39.305344Z","iopub.status.idle":"2021-06-12T14:22:44.821067Z","shell.execute_reply.started":"2021-06-12T12:06:39.305307Z","shell.execute_reply":"2021-06-12T14:22:44.819728Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"episode  0 score -117.46 trailing 10 games avg -117.462: trailing 100 games avg -117.462: timesteps: 83\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:259: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","output_type":"stream"},{"name":"stdout","text":"episode  1 score -46.36 timesteps: 1683\nepisode  2 score -118.37 timesteps: 1726\nepisode  3 score -107.47 timesteps: 1811\nepisode  4 score -112.72 timesteps: 1916\nepisode  5 score -114.21 timesteps: 2103\nepisode  6 score -116.16 timesteps: 2178\nepisode  7 score -109.69 timesteps: 2266\nepisode  8 score -111.85 timesteps: 2380\nepisode  9 score -113.94 timesteps: 2525\nepisode  10 score -123.58 trailing 10 games avg -107.434: trailing 100 games avg -108.346: timesteps: 2572\nepisode  11 score -114.20 timesteps: 2777\nepisode  12 score -116.46 timesteps: 2821\nepisode  13 score -111.07 timesteps: 2947\nepisode  14 score -112.10 timesteps: 3030\nepisode  15 score -105.32 timesteps: 4630\nepisode  16 score -111.59 timesteps: 6230\nepisode  17 score -103.67 timesteps: 6314\nepisode  18 score -116.62 timesteps: 6376\nepisode  19 score -115.54 timesteps: 6438\nepisode  20 score -93.93 trailing 10 games avg -110.050: trailing 100 games avg -109.157: timesteps: 8038\nepisode  21 score -82.13 timesteps: 9638\nepisode  22 score -98.78 timesteps: 9775\nepisode  23 score -124.92 timesteps: 9965\nepisode  24 score -125.50 timesteps: 11565\nepisode  25 score -111.38 timesteps: 11698\nepisode  26 score -113.27 timesteps: 11799\nepisode  27 score -108.31 timesteps: 11886\nepisode  28 score -110.30 timesteps: 11949\nepisode  29 score -128.84 timesteps: 12144\nepisode  30 score -119.42 trailing 10 games avg -112.286: trailing 100 games avg -110.167: timesteps: 12257\nepisode  31 score -112.28 timesteps: 12383\nepisode  32 score -103.67 timesteps: 12466\nepisode  33 score -124.75 timesteps: 12585\nepisode  34 score -102.61 timesteps: 12739\nepisode  35 score -102.38 timesteps: 12848\nepisode  36 score -119.49 timesteps: 12966\nepisode  37 score -118.12 timesteps: 13076\nepisode  38 score -82.26 timesteps: 14676\nepisode  39 score -97.07 timesteps: 16276\nepisode  40 score -100.07 trailing 10 games avg -106.270: trailing 100 games avg -109.216: timesteps: 16361\nepisode  41 score -85.63 timesteps: 17961\nepisode  42 score -98.07 timesteps: 18059\nepisode  43 score -100.57 timesteps: 18127\nepisode  44 score -102.70 timesteps: 18184\nepisode  45 score -112.84 timesteps: 18252\nepisode  46 score -106.06 timesteps: 18335\nepisode  47 score -105.16 timesteps: 18500\nepisode  48 score -87.60 timesteps: 20100\nepisode  49 score -120.16 timesteps: 20176\nepisode  50 score -116.12 trailing 10 games avg -103.491: trailing 100 games avg -108.094: timesteps: 20266\nepisode  51 score -88.64 timesteps: 21866\nepisode  52 score -114.45 timesteps: 21915\nepisode  53 score -79.01 timesteps: 23515\nepisode  54 score -130.48 timesteps: 23610\nepisode  55 score -137.43 timesteps: 23766\nepisode  56 score -74.13 timesteps: 25366\nepisode  57 score -116.91 timesteps: 25523\nepisode  58 score -102.04 timesteps: 25609\nepisode  59 score -132.85 timesteps: 25758\nepisode  60 score -137.77 trailing 10 games avg -111.371: trailing 100 games avg -108.631: timesteps: 25921\nepisode  61 score -136.33 timesteps: 26061\nepisode  62 score -134.28 timesteps: 26200\nepisode  63 score -110.45 timesteps: 26344\nepisode  64 score -114.16 timesteps: 26483\nepisode  65 score -134.75 timesteps: 26596\nepisode  66 score -118.03 timesteps: 26667\nepisode  67 score -110.71 timesteps: 26783\nepisode  68 score -109.94 timesteps: 26883\nepisode  69 score -113.34 timesteps: 26938\nepisode  70 score -111.70 trailing 10 games avg -119.370: trailing 100 games avg -110.143: timesteps: 27016\nepisode  71 score -116.07 timesteps: 27091\nepisode  72 score -111.94 timesteps: 27154\nepisode  73 score -109.01 timesteps: 27246\nepisode  74 score -114.66 timesteps: 27437\nepisode  75 score -120.96 timesteps: 27540\nepisode  76 score -105.56 timesteps: 27666\nepisode  77 score -104.28 timesteps: 27763\nepisode  78 score -107.47 timesteps: 27838\nepisode  79 score -136.60 timesteps: 28064\nepisode  80 score -105.56 trailing 10 games avg -113.210: trailing 100 games avg -110.522: timesteps: 28185\nepisode  81 score -112.15 timesteps: 28305\nepisode  82 score -105.21 timesteps: 28391\nepisode  83 score -109.16 timesteps: 28510\nepisode  84 score -109.60 timesteps: 28626\nepisode  85 score -144.11 timesteps: 30170\nepisode  86 score -58.61 timesteps: 31770\nepisode  87 score -109.16 timesteps: 31880\nepisode  88 score -84.03 timesteps: 33480\nepisode  89 score -109.83 timesteps: 33531\nepisode  90 score -102.45 trailing 10 games avg -104.430: trailing 100 games avg -109.853: timesteps: 33622\nepisode  91 score -103.84 timesteps: 33723\nepisode  92 score -108.39 timesteps: 33848\nepisode  93 score -112.03 timesteps: 33972\nepisode  94 score -133.33 timesteps: 34545\nepisode  95 score -103.48 timesteps: 34667\nepisode  96 score -129.52 timesteps: 34783\nepisode  97 score -117.63 timesteps: 34892\nepisode  98 score -129.25 timesteps: 35089\nepisode  99 score -168.60 timesteps: 36528\nepisode  100 score -88.91 trailing 10 games avg -119.497: trailing 100 games avg -110.741: timesteps: 38128\nepisode  101 score -74.37 timesteps: 39728\nepisode  102 score -65.20 timesteps: 41328\nepisode  103 score -73.63 timesteps: 42928\nepisode  104 score -56.32 timesteps: 44528\nepisode  105 score -110.06 timesteps: 44661\nepisode  106 score -104.69 timesteps: 44744\nepisode  107 score -115.55 timesteps: 45900\nepisode  108 score -34.95 timesteps: 47500\nepisode  109 score -71.93 timesteps: 49100\nepisode  110 score -113.83 trailing 10 games avg -82.052: trailing 100 games avg -108.203: timesteps: 49151\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to :  0.35\n--------------------------------------------------------------------------------------------\nepisode  111 score -77.23 timesteps: 50751\nepisode  112 score -126.25 timesteps: 50881\nepisode  113 score -112.15 timesteps: 50984\nepisode  114 score -120.80 timesteps: 51209\nepisode  115 score -106.74 timesteps: 51271\nepisode  116 score -109.10 timesteps: 51349\nepisode  117 score -106.88 timesteps: 51393\nepisode  118 score -82.11 timesteps: 52993\nepisode  119 score -79.02 timesteps: 54593\nepisode  120 score -87.81 trailing 10 games avg -100.808: trailing 100 games avg -107.279: timesteps: 56193\nepisode  121 score -105.11 timesteps: 56277\nepisode  122 score -95.31 timesteps: 57877\nepisode  123 score -101.89 timesteps: 58013\nepisode  124 score -92.01 timesteps: 59613\nepisode  125 score -115.02 timesteps: 59710\nepisode  126 score -63.00 timesteps: 61310\nepisode  127 score -116.86 timesteps: 61437\nepisode  128 score -110.59 timesteps: 61532\nepisode  129 score -63.51 timesteps: 63132\nepisode  130 score -71.35 trailing 10 games avg -93.465: trailing 100 games avg -105.397: timesteps: 64732\nepisode  131 score -43.97 timesteps: 66332\nepisode  132 score -49.76 timesteps: 67932\nepisode  133 score -104.87 timesteps: 68019\nepisode  134 score -105.23 timesteps: 68107\nepisode  135 score -101.35 timesteps: 68226\nepisode  136 score -58.58 timesteps: 69826\nepisode  137 score -13.40 timesteps: 71426\nepisode  138 score 2.13 timesteps: 73026\nepisode  139 score -105.13 timesteps: 73099\nepisode  140 score -109.05 trailing 10 games avg -68.923: trailing 100 games avg -101.662: timesteps: 73183\nepisode  141 score -115.27 timesteps: 73274\nepisode  142 score -117.08 timesteps: 73345\nepisode  143 score -69.75 timesteps: 74945\nepisode  144 score -79.16 timesteps: 76545\nepisode  145 score -111.55 timesteps: 78145\nepisode  146 score -59.05 timesteps: 79745\nepisode  147 score -118.07 timesteps: 79824\nepisode  148 score -87.67 timesteps: 81424\nepisode  149 score -99.29 timesteps: 83024\nepisode  150 score -77.68 trailing 10 games avg -93.458: trailing 100 games avg -100.659: timesteps: 84624\nepisode  151 score -84.13 timesteps: 86224\nepisode  152 score -74.84 timesteps: 87824\nepisode  153 score -89.36 timesteps: 89424\nepisode  154 score -82.02 timesteps: 91024\nepisode  155 score -116.72 timesteps: 91080\nepisode  156 score -85.54 timesteps: 92680\nepisode  157 score -60.60 timesteps: 94280\nepisode  158 score -136.22 timesteps: 94424\nepisode  159 score -116.58 timesteps: 94535\nepisode  160 score -126.84 trailing 10 games avg -97.284: trailing 100 games avg -99.250: timesteps: 94616\nepisode  161 score -123.02 timesteps: 94728\nepisode  162 score -112.01 timesteps: 94817\nepisode  163 score -135.08 timesteps: 95138\nepisode  164 score -129.59 timesteps: 95265\nepisode  165 score -74.18 timesteps: 96865\nepisode  166 score -98.02 timesteps: 98465\nepisode  167 score -170.16 timesteps: 99204\nepisode  168 score -160.43 timesteps: 99765\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to :  0.3\n--------------------------------------------------------------------------------------------\nepisode  169 score -167.37 timesteps: 100457\nepisode  170 score -197.51 trailing 10 games avg -136.735: trailing 100 games avg -100.986: timesteps: 101653\nepisode  171 score -101.31 timesteps: 101751\nepisode  172 score -178.77 timesteps: 102632\nepisode  173 score -74.81 timesteps: 104232\nepisode  174 score -74.47 timesteps: 105832\nepisode  175 score -134.67 timesteps: 106005\nepisode  176 score -127.53 timesteps: 106128\nepisode  177 score -77.33 timesteps: 107728\nepisode  178 score -119.83 timesteps: 107806\nepisode  179 score -104.82 timesteps: 108030\nepisode  180 score -129.00 trailing 10 games avg -112.253: trailing 100 games avg -100.891: timesteps: 108126\nepisode  181 score -64.39 timesteps: 109726\nepisode  182 score -95.06 timesteps: 111326\nepisode  183 score -43.48 timesteps: 112926\nepisode  184 score -124.84 timesteps: 112995\nepisode  185 score -126.41 timesteps: 113071\nepisode  186 score -113.72 timesteps: 113138\nepisode  187 score -128.25 timesteps: 113227\nepisode  188 score -126.57 timesteps: 113305\nepisode  189 score -119.15 timesteps: 113413\nepisode  190 score -123.23 trailing 10 games avg -106.512: trailing 100 games avg -101.099: timesteps: 113479\nepisode  191 score -123.62 timesteps: 113566\nepisode  192 score -124.95 timesteps: 113657\nepisode  193 score -123.61 timesteps: 113738\nepisode  194 score -126.04 timesteps: 113818\nepisode  195 score -140.98 timesteps: 113928\nepisode  196 score -123.36 timesteps: 114015\nepisode  197 score -126.86 timesteps: 114100\nepisode  198 score -126.90 timesteps: 114192\nepisode  199 score -126.73 timesteps: 114286\nepisode  200 score -136.67 trailing 10 games avg -127.971: trailing 100 games avg -101.946: timesteps: 114394\nepisode  201 score -60.02 timesteps: 115994\nepisode  202 score -121.18 timesteps: 116080\nepisode  203 score -127.18 timesteps: 116160\nepisode  204 score -121.60 timesteps: 116227\nepisode  205 score -122.76 timesteps: 116313\nepisode  206 score -121.45 timesteps: 116386\nepisode  207 score -123.79 timesteps: 116466\nepisode  208 score -122.02 timesteps: 116542\nepisode  209 score -120.54 timesteps: 116618\nepisode  210 score -123.47 trailing 10 games avg -116.402: trailing 100 games avg -105.381: timesteps: 116708\nepisode  211 score -124.73 timesteps: 116801\nepisode  212 score -122.28 timesteps: 116881\nepisode  213 score -121.94 timesteps: 116946\nepisode  214 score -121.45 timesteps: 117009\nepisode  215 score -119.74 timesteps: 117068\nepisode  216 score -120.56 timesteps: 117134\nepisode  217 score -121.80 timesteps: 117201\nepisode  218 score -119.57 timesteps: 117264\nepisode  219 score -129.36 timesteps: 117363\nepisode  220 score -129.17 trailing 10 games avg -123.061: trailing 100 games avg -107.606: timesteps: 117442\nepisode  221 score -125.78 timesteps: 117522\nepisode  222 score -122.24 timesteps: 117845\nepisode  223 score -128.11 timesteps: 117921\nepisode  224 score -129.16 timesteps: 118732\nepisode  225 score -69.89 timesteps: 120332\nepisode  226 score -76.23 timesteps: 121932\nepisode  227 score -114.32 timesteps: 122161\nepisode  228 score -122.10 timesteps: 123204\nepisode  229 score -134.30 timesteps: 123505\nepisode  230 score -122.78 trailing 10 games avg -114.492: trailing 100 games avg -109.709: timesteps: 123642\nepisode  231 score -107.41 timesteps: 123840\nepisode  232 score -101.26 timesteps: 124383\nepisode  233 score -103.71 timesteps: 124513\nepisode  234 score -118.85 timesteps: 124587\nepisode  235 score -105.47 timesteps: 124861\nepisode  236 score -100.10 timesteps: 124926\nepisode  237 score -86.93 timesteps: 125185\nepisode  238 score -106.07 timesteps: 125487\nepisode  239 score -117.91 timesteps: 125561\nepisode  240 score -59.46 trailing 10 games avg -100.718: trailing 100 games avg -112.889: timesteps: 127161\nepisode  241 score -104.45 timesteps: 127269\nepisode  242 score -95.34 timesteps: 127466\nepisode  243 score -114.45 timesteps: 127648\nepisode  244 score -119.45 timesteps: 127958\nepisode  245 score -117.17 timesteps: 128033\nepisode  246 score -99.65 timesteps: 128316\nepisode  247 score -121.87 timesteps: 128615\nepisode  248 score -133.44 timesteps: 129059\nepisode  249 score -112.55 timesteps: 129468\nepisode  250 score -95.35 trailing 10 games avg -111.371: trailing 100 games avg -114.680: timesteps: 129551\nepisode  251 score -82.52 timesteps: 129817\nepisode  252 score -202.13 timesteps: 130878\nepisode  253 score -121.46 timesteps: 130985\nepisode  254 score -110.80 timesteps: 131141\nepisode  255 score -135.70 timesteps: 131395\nepisode  256 score -143.80 timesteps: 132911\nepisode  257 score -117.09 timesteps: 133185\nepisode  258 score -107.25 timesteps: 133313\nepisode  259 score -100.57 timesteps: 133373\nepisode  260 score -124.09 trailing 10 games avg -124.541: trailing 100 games avg -117.406: timesteps: 133532\nepisode  261 score -127.55 timesteps: 133772\nepisode  262 score -124.94 timesteps: 133913\nepisode  263 score -36.90 timesteps: 135513\nepisode  264 score -132.75 timesteps: 135746\nepisode  265 score -122.63 timesteps: 136060\nepisode  266 score -116.46 timesteps: 136443\nepisode  267 score -122.49 timesteps: 136570\nepisode  268 score -115.25 timesteps: 136719\nepisode  269 score -130.27 timesteps: 137030\nepisode  270 score -105.62 trailing 10 games avg -113.487: trailing 100 games avg -115.081: timesteps: 137129\nepisode  271 score -63.28 timesteps: 138729\nepisode  272 score -26.59 timesteps: 140329\nepisode  273 score -128.43 timesteps: 140501\nepisode  274 score -124.89 timesteps: 140758\nepisode  275 score -123.53 timesteps: 140909\nepisode  276 score -110.89 timesteps: 141244\nepisode  277 score -126.55 timesteps: 141584\nepisode  278 score -120.53 timesteps: 141657\nepisode  279 score -111.61 timesteps: 141720\nepisode  280 score -160.24 trailing 10 games avg -109.655: trailing 100 games avg -114.821: timesteps: 142414\nepisode  281 score -111.60 timesteps: 142483\nepisode  282 score -133.12 timesteps: 142630\nepisode  283 score -114.74 timesteps: 142718\nepisode  284 score -137.70 timesteps: 142959\nepisode  285 score -111.60 timesteps: 143158\nepisode  286 score -125.96 timesteps: 143263\nepisode  287 score -108.04 timesteps: 143402\nepisode  288 score -101.09 timesteps: 143989\nepisode  289 score -149.44 timesteps: 145427\nepisode  290 score -110.35 trailing 10 games avg -120.365: trailing 100 games avg -116.206: timesteps: 145650\nepisode  291 score -91.53 timesteps: 146258\nepisode  292 score -144.83 timesteps: 147677\nepisode  293 score -113.54 timesteps: 147819\nepisode  294 score -84.42 timesteps: 148705\nepisode  295 score -182.43 timesteps: 149688\nepisode  296 score -94.13 timesteps: 149978\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to :  0.25\n--------------------------------------------------------------------------------------------\nepisode  297 score -100.88 timesteps: 150368\nepisode  298 score -139.03 timesteps: 151915\nepisode  299 score -136.88 timesteps: 152612\nepisode  300 score -108.84 trailing 10 games avg -119.652: trailing 100 games avg -115.374: timesteps: 154212\nepisode  301 score -125.25 timesteps: 155812\nepisode  302 score -168.74 timesteps: 156519\nepisode  303 score -99.04 timesteps: 156680\nepisode  304 score -196.84 timesteps: 158135\nepisode  305 score -116.46 timesteps: 158231\nepisode  306 score -108.24 timesteps: 159831\nepisode  307 score -75.66 timesteps: 161431\nepisode  308 score -112.06 timesteps: 163031\nepisode  309 score -99.89 timesteps: 164631\nepisode  310 score -94.49 trailing 10 games avg -119.668: trailing 100 games avg -115.701: timesteps: 166231\nepisode  311 score -117.86 timesteps: 167831\nepisode  312 score -105.22 timesteps: 169431\nepisode  313 score -105.73 timesteps: 171031\nepisode  314 score -107.30 timesteps: 172631\nepisode  315 score -84.41 timesteps: 174231\nepisode  316 score -48.34 timesteps: 175831\nepisode  317 score -111.27 timesteps: 177431\nepisode  318 score -98.51 timesteps: 179031\nepisode  319 score -102.82 timesteps: 180631\nepisode  320 score -104.85 trailing 10 games avg -98.631: trailing 100 games avg -113.258: timesteps: 182231\nepisode  321 score -98.62 timesteps: 183831\nepisode  322 score -93.67 timesteps: 185431\nepisode  323 score -163.62 timesteps: 186319\nepisode  324 score -123.68 timesteps: 186974\nepisode  325 score -105.82 timesteps: 188574\nepisode  326 score -183.43 timesteps: 190064\nepisode  327 score 4.02 timesteps: 191664\nepisode  328 score -28.96 timesteps: 193264\nepisode  329 score -135.12 timesteps: 193885\nepisode  330 score -94.47 trailing 10 games avg -102.337: trailing 100 games avg -112.042: timesteps: 193994\nepisode  331 score -99.44 timesteps: 194259\nepisode  332 score -92.03 timesteps: 195859\nepisode  333 score -105.48 timesteps: 196068\nepisode  334 score -132.73 timesteps: 197223\nepisode  335 score -206.37 timesteps: 198372\nepisode  336 score -31.54 timesteps: 199972\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to :  0.2\n--------------------------------------------------------------------------------------------\nepisode  337 score -98.33 timesteps: 201572\nepisode  338 score -160.01 timesteps: 202914\nepisode  339 score -87.30 timesteps: 204514\nepisode  340 score -105.47 trailing 10 games avg -111.869: trailing 100 games avg -113.158: timesteps: 206114\nepisode  341 score -56.24 timesteps: 207714\nepisode  342 score -107.83 timesteps: 209314\nepisode  343 score -38.15 timesteps: 210914\nepisode  344 score -84.10 timesteps: 212514\nepisode  345 score -70.71 timesteps: 214114\nepisode  346 score -80.08 timesteps: 215714\nepisode  347 score -27.81 timesteps: 217314\nepisode  348 score -50.88 timesteps: 218914\nepisode  349 score -95.50 timesteps: 220514\nepisode  350 score -144.46 trailing 10 games avg -75.575: trailing 100 games avg -109.578: timesteps: 221871\nepisode  351 score -100.31 timesteps: 222044\nepisode  352 score -105.17 timesteps: 222342\nepisode  353 score -81.93 timesteps: 223942\nepisode  354 score -121.95 timesteps: 224245\nepisode  355 score -78.01 timesteps: 225845\nepisode  356 score -96.93 timesteps: 226098\nepisode  357 score -87.64 timesteps: 227698\nepisode  358 score -57.61 timesteps: 229298\nepisode  359 score -191.95 timesteps: 230213\nepisode  360 score -81.94 trailing 10 games avg -100.343: trailing 100 games avg -107.158: timesteps: 231813\nepisode  361 score -152.48 timesteps: 232600\nepisode  362 score -59.32 timesteps: 234200\nepisode  363 score -59.54 timesteps: 235800\nepisode  364 score -17.80 timesteps: 237400\nepisode  365 score -176.79 timesteps: 238719\nepisode  366 score -54.17 timesteps: 240319\nepisode  367 score -56.79 timesteps: 241919\nepisode  368 score -133.43 timesteps: 242295\nepisode  369 score -75.52 timesteps: 243895\nepisode  370 score -62.79 trailing 10 games avg -84.863: trailing 100 games avg -104.296: timesteps: 245495\nepisode  371 score -144.17 timesteps: 245846\nepisode  372 score -75.18 timesteps: 247446\nepisode  373 score -38.65 timesteps: 249046\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to :  0.15\n--------------------------------------------------------------------------------------------\nepisode  374 score -172.20 timesteps: 250037\nepisode  375 score -165.41 timesteps: 250898\nepisode  376 score -88.91 timesteps: 252498\nepisode  377 score -30.87 timesteps: 254098\nepisode  378 score -20.13 timesteps: 255698\nepisode  379 score -62.13 timesteps: 257298\nepisode  380 score -61.67 trailing 10 games avg -85.931: trailing 100 games avg -101.924: timesteps: 258898\nepisode  381 score -132.82 timesteps: 260498\nepisode  382 score -101.10 timesteps: 262098\nepisode  383 score -101.31 timesteps: 263698\nepisode  384 score -115.45 timesteps: 265298\nepisode  385 score -93.89 timesteps: 265525\nepisode  386 score -72.21 timesteps: 267125\nepisode  387 score -62.92 timesteps: 268725\nepisode  388 score -104.11 timesteps: 270325\nepisode  389 score -33.11 timesteps: 271925\nepisode  390 score -108.49 trailing 10 games avg -92.540: trailing 100 games avg -99.141: timesteps: 273525\nepisode  391 score -65.08 timesteps: 275125\nepisode  392 score -112.73 timesteps: 276725\nepisode  393 score -70.34 timesteps: 278325\nepisode  394 score -86.16 timesteps: 279925\nepisode  395 score -65.69 timesteps: 281525\nepisode  396 score -11.61 timesteps: 283125\nepisode  397 score -16.47 timesteps: 284725\nepisode  398 score 33.02 timesteps: 286325\nepisode  399 score -3.05 timesteps: 287925\nepisode  400 score -12.51 trailing 10 games avg -41.061: trailing 100 games avg -91.282: timesteps: 289525\nepisode  401 score -84.37 timesteps: 291125\nepisode  402 score 73.05 timesteps: 292725\nepisode  403 score -16.67 timesteps: 294325\nepisode  404 score -91.78 timesteps: 295925\nepisode  405 score -96.73 timesteps: 297525\nepisode  406 score -99.74 timesteps: 299125\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  407 score -102.43 timesteps: 300725\nepisode  408 score -201.06 timesteps: 302128\nepisode  409 score -100.39 timesteps: 303728\nepisode  410 score -196.90 trailing 10 games avg -91.702: trailing 100 games avg -88.485: timesteps: 305020\nepisode  411 score -95.98 timesteps: 306620\nepisode  412 score -79.69 timesteps: 308220\nepisode  413 score -67.69 timesteps: 309820\nepisode  414 score -71.16 timesteps: 311420\nepisode  415 score 30.23 timesteps: 313020\nepisode  416 score -71.23 timesteps: 314620\nepisode  417 score -79.58 timesteps: 316220\nepisode  418 score -65.48 timesteps: 317820\nepisode  419 score -76.90 timesteps: 319420\nepisode  420 score -71.98 trailing 10 games avg -64.947: trailing 100 games avg -85.117: timesteps: 321020\nepisode  421 score -72.05 timesteps: 322620\nepisode  422 score -71.82 timesteps: 324220\nepisode  423 score -44.45 timesteps: 325820\nepisode  424 score -83.48 timesteps: 327420\nepisode  425 score -74.06 timesteps: 329020\nepisode  426 score -31.12 timesteps: 330620\nepisode  427 score -26.01 timesteps: 332220\nepisode  428 score -37.55 timesteps: 333820\nepisode  429 score -6.55 timesteps: 335420\nepisode  430 score 75.32 trailing 10 games avg -37.177: trailing 100 games avg -78.601: timesteps: 337020\nepisode  431 score 13.92 timesteps: 338620\nepisode  432 score 35.63 timesteps: 340220\nepisode  433 score 41.17 timesteps: 341820\nepisode  434 score 12.33 timesteps: 343420\nepisode  435 score 30.94 timesteps: 345020\nepisode  436 score 13.49 timesteps: 346620\nepisode  437 score 61.35 timesteps: 348220\nepisode  438 score 10.59 timesteps: 349820\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  439 score 18.65 timesteps: 351420\nepisode  440 score -23.54 trailing 10 games avg 21.452: trailing 100 games avg -65.269: timesteps: 353020\nepisode  441 score -35.96 timesteps: 354620\nepisode  442 score 2.48 timesteps: 356220\nepisode  443 score -35.14 timesteps: 357820\nepisode  444 score -97.14 timesteps: 359420\nepisode  445 score -61.28 timesteps: 361020\nepisode  446 score -34.37 timesteps: 362620\nepisode  447 score -35.22 timesteps: 364220\nepisode  448 score -61.10 timesteps: 365820\nepisode  449 score -77.23 timesteps: 367420\nepisode  450 score -58.31 trailing 10 games avg -49.328: trailing 100 games avg -62.644: timesteps: 369020\nepisode  451 score -46.84 timesteps: 370620\nepisode  452 score -63.63 timesteps: 372220\nepisode  453 score 69.53 timesteps: 373820\nepisode  454 score -50.22 timesteps: 375420\nepisode  455 score -55.60 timesteps: 377020\nepisode  456 score 49.92 timesteps: 378620\nepisode  457 score -75.17 timesteps: 380220\nepisode  458 score -7.41 timesteps: 381820\nepisode  459 score -40.66 timesteps: 383420\nepisode  460 score 59.70 trailing 10 games avg -16.039: trailing 100 games avg -54.214: timesteps: 385020\nepisode  461 score -53.45 timesteps: 386620\nepisode  462 score 43.95 timesteps: 388220\nepisode  463 score 26.75 timesteps: 389820\nepisode  464 score 83.85 timesteps: 391420\nepisode  465 score -46.63 timesteps: 393020\nepisode  466 score -53.39 timesteps: 394620\nepisode  467 score -45.28 timesteps: 396220\nepisode  468 score -107.66 timesteps: 397820\nepisode  469 score -84.99 timesteps: 399420\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  470 score -112.28 trailing 10 games avg -34.913: trailing 100 games avg -49.219: timesteps: 401020\nepisode  471 score 90.71 timesteps: 402620\nepisode  472 score 106.07 timesteps: 404220\nepisode  473 score -93.72 timesteps: 405820\nepisode  474 score -92.06 timesteps: 407420\nepisode  475 score -97.68 timesteps: 409020\nepisode  476 score 25.28 timesteps: 410620\nepisode  477 score -31.44 timesteps: 412220\nepisode  478 score -93.48 timesteps: 413820\nepisode  479 score -37.28 timesteps: 415420\nepisode  480 score -51.89 trailing 10 games avg -27.549: trailing 100 games avg -43.380: timesteps: 417020\nepisode  481 score -33.46 timesteps: 418620\nepisode  482 score -17.31 timesteps: 420220\nepisode  483 score -74.56 timesteps: 421072\nepisode  484 score 43.89 timesteps: 422672\nepisode  485 score 99.02 timesteps: 424272\nepisode  486 score 157.01 timesteps: 425872\nepisode  487 score 123.62 timesteps: 427472\nepisode  488 score -23.94 timesteps: 428615\nepisode  489 score 93.47 timesteps: 430215\nepisode  490 score 71.17 trailing 10 games avg 43.891: trailing 100 games avg -29.737: timesteps: 431815\nepisode  491 score 86.82 timesteps: 433415\nepisode  492 score 106.53 timesteps: 435015\nepisode  493 score 144.90 timesteps: 436615\nepisode  494 score 102.37 timesteps: 438215\nepisode  495 score -61.26 timesteps: 439111\nepisode  496 score 133.47 timesteps: 440711\nepisode  497 score 73.71 timesteps: 442311\nepisode  498 score -131.92 timesteps: 442504\nepisode  499 score -85.65 timesteps: 443534\nepisode  500 score 152.89 trailing 10 games avg 52.184: trailing 100 games avg -20.413: timesteps: 445134\nepisode  501 score 209.74 timesteps: 446734\nepisode  502 score 117.17 timesteps: 448334\nepisode  503 score 280.46 timesteps: 449817\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  504 score -38.86 timesteps: 450134\nepisode  505 score -54.54 timesteps: 450390\nepisode  506 score -64.04 timesteps: 450613\nepisode  507 score -83.93 timesteps: 450799\nepisode  508 score -57.90 timesteps: 451073\nepisode  509 score -68.25 timesteps: 451257\nepisode  510 score -57.22 trailing 10 games avg 18.262: trailing 100 games avg -9.416: timesteps: 451485\nepisode  511 score -14.25 timesteps: 451979\nepisode  512 score 150.18 timesteps: 453289\nepisode  513 score 271.48 timesteps: 454801\nepisode  514 score 276.65 timesteps: 456209\nepisode  515 score 254.33 timesteps: 457809\nepisode  516 score 232.73 timesteps: 459409\nepisode  517 score 154.15 timesteps: 461009\nepisode  518 score 222.20 timesteps: 462609\nepisode  519 score 272.25 timesteps: 464142\nepisode  520 score 224.63 trailing 10 games avg 204.434: trailing 100 games avg 17.522: timesteps: 465742\nepisode  521 score 211.81 timesteps: 467342\nepisode  522 score 203.99 timesteps: 468942\nepisode  523 score 151.05 timesteps: 470542\nepisode  524 score 157.59 timesteps: 472142\nepisode  525 score 142.26 timesteps: 473742\nepisode  526 score -4.62 timesteps: 474254\nepisode  527 score 231.75 timesteps: 475854\nepisode  528 score 39.09 timesteps: 477454\nepisode  529 score -22.48 timesteps: 477903\nepisode  530 score 4.44 trailing 10 games avg 111.488: trailing 100 games avg 32.388: timesteps: 478442\nepisode  531 score 56.73 timesteps: 479465\nepisode  532 score 283.65 timesteps: 480764\nepisode  533 score 149.70 timesteps: 482364\nepisode  534 score 236.95 timesteps: 483964\nepisode  535 score 281.76 timesteps: 485441\nepisode  536 score 264.91 timesteps: 487041\nepisode  537 score 269.72 timesteps: 488641\nepisode  538 score 241.95 timesteps: 490241\nepisode  539 score 292.75 timesteps: 491655\nepisode  540 score 259.41 trailing 10 games avg 233.753: trailing 100 games avg 53.618: timesteps: 493255\nepisode  541 score 17.59 timesteps: 494855\nepisode  542 score 94.57 timesteps: 496455\nepisode  543 score 289.00 timesteps: 497861\nepisode  544 score 4.38 timesteps: 499461\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  545 score 29.38 timesteps: 501061\nepisode  546 score 293.26 timesteps: 502322\nepisode  547 score 286.13 timesteps: 503728\nepisode  548 score 86.98 timesteps: 505328\nepisode  549 score 289.77 timesteps: 506787\nepisode  550 score 291.50 trailing 10 games avg 168.256: trailing 100 games avg 75.377: timesteps: 508254\nepisode  551 score 297.35 timesteps: 509474\nepisode  552 score 296.76 timesteps: 510823\nepisode  553 score 295.42 timesteps: 512145\nepisode  554 score 299.07 timesteps: 513449\nepisode  555 score 287.39 timesteps: 514995\nepisode  556 score 294.56 timesteps: 516528\nepisode  557 score 100.65 timesteps: 517473\nepisode  558 score 95.88 timesteps: 519073\nepisode  559 score 289.00 timesteps: 520459\nepisode  560 score -116.83 trailing 10 games avg 213.924: trailing 100 games avg 98.373: timesteps: 520517\nepisode  561 score 286.20 timesteps: 522117\nepisode  562 score -132.45 timesteps: 522259\nepisode  563 score -59.88 timesteps: 523859\nepisode  564 score 293.99 timesteps: 525283\nepisode  565 score 297.81 timesteps: 526576\nepisode  566 score -99.05 timesteps: 528176\nepisode  567 score 301.53 timesteps: 529319\nepisode  568 score -95.82 timesteps: 530919\nepisode  569 score -137.41 timesteps: 531665\nepisode  570 score -121.53 trailing 10 games avg 53.340: trailing 100 games avg 107.198: timesteps: 533265\nepisode  571 score -83.81 timesteps: 534865\nepisode  572 score -80.85 timesteps: 536465\nepisode  573 score -114.34 timesteps: 538065\nepisode  574 score -111.85 timesteps: 539665\nepisode  575 score -135.73 timesteps: 541265\nepisode  576 score -109.02 timesteps: 542865\nepisode  577 score -98.23 timesteps: 544465\nepisode  578 score -105.71 timesteps: 546065\nepisode  579 score -65.65 timesteps: 547665\nepisode  580 score -62.59 trailing 10 games avg -96.778: trailing 100 games avg 100.275: timesteps: 549265\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  581 score -53.16 timesteps: 550865\nepisode  582 score -51.03 timesteps: 552465\nepisode  583 score -41.87 timesteps: 554065\nepisode  584 score -63.51 timesteps: 555665\nepisode  585 score -75.08 timesteps: 557265\nepisode  586 score -68.92 timesteps: 558865\nepisode  587 score -51.25 timesteps: 560465\nepisode  588 score -45.35 timesteps: 562065\nepisode  589 score -31.93 timesteps: 563665\nepisode  590 score -65.30 trailing 10 games avg -54.739: trailing 100 games avg 90.412: timesteps: 565265\nepisode  591 score -35.58 timesteps: 566865\nepisode  592 score -4.77 timesteps: 568465\nepisode  593 score 2.64 timesteps: 570065\nepisode  594 score -109.85 timesteps: 571665\nepisode  595 score -90.14 timesteps: 573265\nepisode  596 score -90.33 timesteps: 574865\nepisode  597 score -12.46 timesteps: 576465\nepisode  598 score -3.21 timesteps: 578065\nepisode  599 score 32.65 timesteps: 579665\nepisode  600 score 52.33 trailing 10 games avg -25.873: trailing 100 games avg 82.607: timesteps: 581265\nepisode  601 score 53.42 timesteps: 582865\nepisode  602 score 87.81 timesteps: 584465\nepisode  603 score 73.57 timesteps: 586065\nepisode  604 score 138.73 timesteps: 587665\nepisode  605 score 153.13 timesteps: 589265\nepisode  606 score 186.84 timesteps: 590865\nepisode  607 score 203.94 timesteps: 592465\nepisode  608 score 207.68 timesteps: 594065\nepisode  609 score 223.36 timesteps: 595665\nepisode  610 score 281.95 trailing 10 games avg 161.043: trailing 100 games avg 96.885: timesteps: 597231\nepisode  611 score 281.06 timesteps: 598781\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  612 score 293.98 timesteps: 600147\nepisode  613 score 294.03 timesteps: 601468\nepisode  614 score 293.74 timesteps: 602722\nepisode  615 score 293.86 timesteps: 603952\nepisode  616 score 291.82 timesteps: 605257\nepisode  617 score 289.16 timesteps: 606529\nepisode  618 score -32.30 timesteps: 606864\nepisode  619 score 285.84 timesteps: 608317\nepisode  620 score 299.65 trailing 10 games avg 259.085: trailing 100 games avg 102.350: timesteps: 609624\nepisode  621 score 301.29 timesteps: 610870\nepisode  622 score 301.29 timesteps: 612100\nepisode  623 score 292.30 timesteps: 613349\nepisode  624 score 294.33 timesteps: 614658\nepisode  625 score 295.52 timesteps: 615883\nepisode  626 score 297.23 timesteps: 617146\nepisode  627 score 295.91 timesteps: 618380\nepisode  628 score 290.55 timesteps: 619646\nepisode  629 score 300.05 timesteps: 620870\nepisode  630 score 291.19 trailing 10 games avg 295.965: trailing 100 games avg 120.798: timesteps: 622170\nepisode  631 score 285.40 timesteps: 623516\nepisode  632 score 287.01 timesteps: 624807\nepisode  633 score 297.29 timesteps: 626067\nepisode  634 score 294.26 timesteps: 627391\nepisode  635 score 297.42 timesteps: 628689\nepisode  636 score 297.07 timesteps: 630011\nepisode  637 score 296.27 timesteps: 631336\nepisode  638 score 302.37 timesteps: 632586\nepisode  639 score 308.34 timesteps: 633811\nepisode  640 score 311.07 trailing 10 games avg 297.649: trailing 100 games avg 127.187: timesteps: 634926\nepisode  641 score 309.60 timesteps: 636000\nepisode  642 score 309.30 timesteps: 637124\nepisode  643 score 309.68 timesteps: 638279\nepisode  644 score 302.91 timesteps: 639489\nepisode  645 score 306.67 timesteps: 640682\nepisode  646 score 308.35 timesteps: 641827\nepisode  647 score 305.48 timesteps: 642956\nepisode  648 score 306.84 timesteps: 644129\nepisode  649 score 305.89 timesteps: 645277\nepisode  650 score 300.90 trailing 10 games avg 306.563: trailing 100 games avg 141.018: timesteps: 646603\nepisode  651 score 305.78 timesteps: 647812\nepisode  652 score 304.18 timesteps: 648929\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  653 score 302.43 timesteps: 650105\nepisode  654 score 299.38 timesteps: 651345\nepisode  655 score 305.37 timesteps: 652523\nepisode  656 score 306.24 timesteps: 653721\nepisode  657 score 310.74 timesteps: 654914\nepisode  658 score 311.74 timesteps: 656081\nepisode  659 score 307.09 timesteps: 657198\nepisode  660 score 306.59 trailing 10 games avg 305.955: trailing 100 games avg 150.221: timesteps: 658432\nepisode  661 score 303.48 timesteps: 659483\nepisode  662 score 305.10 timesteps: 660647\nepisode  663 score 307.74 timesteps: 661712\nepisode  664 score 303.26 timesteps: 662886\nepisode  665 score 309.19 timesteps: 663975\nepisode  666 score 307.99 timesteps: 665102\nepisode  667 score 308.05 timesteps: 666226\nepisode  668 score 305.25 timesteps: 667343\nepisode  669 score 303.46 timesteps: 668448\nepisode  670 score 309.12 trailing 10 games avg 306.263: trailing 100 games avg 175.513: timesteps: 669547\nepisode  671 score 306.68 timesteps: 670676\nepisode  672 score 306.68 timesteps: 671824\nepisode  673 score 308.00 timesteps: 672966\nepisode  674 score 309.35 timesteps: 674137\nepisode  675 score 308.96 timesteps: 675310\nepisode  676 score 310.56 timesteps: 676427\nepisode  677 score 308.00 timesteps: 677608\nepisode  678 score 308.89 timesteps: 678803\nepisode  679 score 304.80 timesteps: 679996\nepisode  680 score 304.40 trailing 10 games avg 307.632: trailing 100 games avg 215.954: timesteps: 681143\nepisode  681 score 306.57 timesteps: 682394\nepisode  682 score 304.97 timesteps: 683628\nepisode  683 score 309.20 timesteps: 684771\nepisode  684 score 307.05 timesteps: 686003\nepisode  685 score 305.80 timesteps: 687231\nepisode  686 score 305.24 timesteps: 688360\nepisode  687 score 307.89 timesteps: 689551\nepisode  688 score 308.00 timesteps: 690748\nepisode  689 score 308.04 timesteps: 691865\nepisode  690 score 308.23 trailing 10 games avg 307.099: trailing 100 games avg 252.138: timesteps: 693014\nepisode  691 score 301.92 timesteps: 694225\nepisode  692 score 306.62 timesteps: 695435\nepisode  693 score 310.70 timesteps: 696587\nepisode  694 score 305.10 timesteps: 697723\nepisode  695 score 306.84 timesteps: 698838\nepisode  696 score 308.88 timesteps: 699935\n--------------------------------------------------------------------------------------------\nsetting actor output action_std to min_action_std :  0.1\n--------------------------------------------------------------------------------------------\nepisode  697 score 307.88 timesteps: 701062\nepisode  698 score 305.30 timesteps: 702265\nepisode  699 score 303.53 timesteps: 703402\nepisode  700 score 310.11 trailing 10 games avg 306.688: trailing 100 games avg 285.394: timesteps: 704515\nepisode  701 score 306.74 timesteps: 705582\nepisode  702 score 310.01 timesteps: 706639\n####SOLVED!!####\n\nEpisode Reward: 306.0928464850192\nEpisode Reward: 306.3062226832709\nEpisode Reward: 306.96085771439664\nEpisode Reward: 307.53992908819896\nEpisode Reward: 308.35254532155926\nEpisode Reward: 308.01476337575593\nEpisode Reward: 305.3933544213734\nEpisode Reward: 308.1728073518987\nEpisode Reward: 307.448313682324\nEpisode Reward: 307.7999109825788\nEpisode Reward: 308.29430602640855\nEpisode Reward: 306.5755548023877\nEpisode Reward: 305.0936211935457\nEpisode Reward: 183.59649984931542\nEpisode Reward: 307.5605280367267\nEpisode Reward: 308.0308534245116\nEpisode Reward: 307.4546128271488\nEpisode Reward: 308.16420482194286\nEpisode Reward: 307.83986114934305\nEpisode Reward: 307.42289789374934\nEpisode Reward: 307.37266084299563\nEpisode Reward: 308.24111071629636\nEpisode Reward: 304.9121559518306\nEpisode Reward: 307.0678169980606\nEpisode Reward: 306.40429350404264\nEpisode Reward: 307.89281831681\nEpisode Reward: 308.01158568413604\nEpisode Reward: 308.5919577197589\nEpisode Reward: 307.05925949971606\nEpisode Reward: 309.0606439363322\nEpisode Reward: 308.6427129314327\nEpisode Reward: 307.2980620140808\nEpisode Reward: 309.1864528325023\nEpisode Reward: 306.46259566170284\nEpisode Reward: 306.77175147414675\nEpisode Reward: 306.40170026906776\nEpisode Reward: 308.02355902453013\nEpisode Reward: 306.0957992276666\nEpisode Reward: 307.74344680759884\nEpisode Reward: 306.48575782866027\nEpisode Reward: 306.6165662825109\nEpisode Reward: 306.5915496542675\nEpisode Reward: 195.04847359869564\nEpisode Reward: 307.535348118137\nEpisode Reward: 306.25771847050584\nEpisode Reward: 306.9725673448089\nEpisode Reward: 307.12144317491396\nEpisode Reward: 307.62236734997174\nEpisode Reward: 307.0602997437104\nEpisode Reward: 308.22144422753564\n\n302.57776820675764\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}